diff --git a/orthoroute/algorithms/manhattan/pathfinder/cuda_dijkstra.py b/orthoroute/algorithms/manhattan/pathfinder/cuda_dijkstra.py
index 706e09c..c1d7ebc 100644
--- a/orthoroute/algorithms/manhattan/pathfinder/cuda_dijkstra.py
+++ b/orthoroute/algorithms/manhattan/pathfinder/cuda_dijkstra.py
@@ -143,6 +143,8 @@ class CUDADijkstra:
             const int indptr_stride,        // Stride between ROI rows (0 for shared CSR!)
             const int indices_stride,       // Stride between ROI rows (0 for shared CSR!)
             const int weights_stride,       // Stride between ROI rows (0 for shared CSR!)
+            const float* total_cost,        // CSR negotiated costs (weights + present + history)
+            const int total_cost_stride,    // Stride for total_cost
             const int* goal_nodes,          // (K,) goal node index for each ROI (for A* heuristic)
             const int Nx,                   // P0-3: Lattice X dimension
             const int Ny,                   // P0-3: Lattice Y dimension
@@ -283,6 +285,8 @@ class CUDADijkstra:
             const int indptr_stride,            // Stride (0 for shared)
             const int indices_stride,
             const int weights_stride,
+            const float* total_cost,            // CSR negotiated costs (weights + present + history)
+            const int total_cost_stride,        // Stride for total_cost
             const int* goal_nodes,              // (K,) goal indices for A*
             const int Nx,                       // P0-3: Lattice X dimension (procedural coords)
             const int Ny,                       // P0-3: Lattice Y dimension
@@ -298,7 +302,10 @@ class CUDADijkstra:
             const int* roi_miny,                // (K,) Min Y per ROI
             const int* roi_maxy,                // (K,) Max Y per ROI
             const int* roi_minz,                // (K,) Min Z per ROI
-            const int* roi_maxz                 // (K,) Max Z per ROI
+            const int* roi_maxz,                // (K,) Max Z per ROI
+            // Phase 5: ROI bitmap for precise gating
+            const unsigned char* roi_bitmap,    // (K, max_roi_size) ROI membership bitmap (nullable)
+            const int roi_bitmap_stride         // Stride for roi_bitmap per ROI
         ) {
             // Global thread ID - each thread processes ONE frontier node
             int idx = blockIdx.x * blockDim.x + threadIdx.x;
@@ -315,6 +322,7 @@ class CUDADijkstra:
             const int total_cost_off = roi_idx * total_cost_stride; // PathFinder negotiated costs
             const int dist_off = roi_idx * max_roi_size;
             const int frontier_off = roi_idx * frontier_words;
+            const int roi_bitmap_off = roi_idx * roi_bitmap_stride; // ROI bitmap offset
 
             // Guarded atomic: Check distance before edge expansion
             const float node_dist = __ldg(&dist[dist_off + node]);
@@ -344,6 +352,11 @@ class CUDADijkstra:
                     continue;  // Skip this neighbor
                 }
 
+                // Phase 5: ROI bitmap check (precise gating after cheap bbox filter)
+                if (roi_bitmap != nullptr && !roi_bitmap[roi_bitmap_off + neighbor]) {
+                    continue;  // Neighbor not in ROI bitmap
+                }
+
                 // P0-3: A* heuristic with PROCEDURAL coordinate decoding (no global loads!)
                 float f_new = g_new;
                 if (use_astar) {
@@ -454,6 +467,7 @@ class CUDADijkstra:
             const int max_roi_size = Nx * Ny * Nz;
             const int dist_off = roi_idx * max_roi_size;
             const int frontier_off = roi_idx * frontier_words;
+            const int roi_bitmap_off = roi_idx * roi_bitmap_stride; // ROI bitmap offset
 
             // Check node distance
             const float node_dist = __ldg(&dist[dist_off + node]);
@@ -1713,7 +1727,13 @@ class CUDADijkstra:
         # Fill arrays from ROI batch
         if not all_share_csr:
             # Only transfer CSR if nets have different ROIs
-            for i, (src, dst, indptr, indices, weights, roi_size) in enumerate(roi_batch):
+            for i, roi_tuple in enumerate(roi_batch):
+                # Handle both 6-element (old) and 7-element (new with roi_bitmap) tuples
+                if len(roi_tuple) == 7:
+                    src, dst, indptr, indices, weights, roi_size, roi_bitmap = roi_tuple
+                else:
+                    src, dst, indptr, indices, weights, roi_size = roi_tuple
+                    roi_bitmap = None  # Old format without ROI bitmap
                 # CRITICAL FIX: Verify indptr has correct size (roi_size + 1)
                 if len(indptr) != roi_size + 1:
                     logger.warning(f"[INDIVIDUAL-CSR-FIX] ROI {i}: indptr size mismatch: len={len(indptr)}, expected={roi_size + 1}")
@@ -1773,8 +1793,33 @@ class CUDADijkstra:
         roi_minz = cp.zeros(K, dtype=cp.int32)
         roi_maxz = cp.zeros(K, dtype=cp.int32)
 
+        # Phase 5: ROI bitmap arrays (for precise device-side gating)
+        batch_roi_bitmap = cp.zeros((K, max_roi_size), dtype=cp.uint8)
+
         # Initialize sources/sinks for all nets
-        for i, (src, dst, indptr, indices, weights, roi_size) in enumerate(roi_batch):
+        for i, roi_tuple in enumerate(roi_batch):
+            # Handle both 6-element (old) and 7-element (new with roi_bitmap) tuples
+            if len(roi_tuple) == 7:
+                src, dst, indptr, indices, weights, roi_size, roi_bitmap = roi_tuple
+            else:
+                src, dst, indptr, indices, weights, roi_size = roi_tuple
+                roi_bitmap = None  # Old format without ROI bitmap
+
+            # Phase 5: Transfer ROI bitmap to GPU if available
+            if roi_bitmap is not None:
+                if not isinstance(roi_bitmap, cp.ndarray):
+                    roi_bitmap = cp.asarray(roi_bitmap, dtype=cp.uint8)
+                # Ensure roi_bitmap is the right size (pad or truncate if needed)
+                if len(roi_bitmap) >= roi_size:
+                    batch_roi_bitmap[i, :roi_size] = roi_bitmap[:roi_size]
+                else:
+                    batch_roi_bitmap[i, :len(roi_bitmap)] = roi_bitmap
+                logger.debug(f"[ROI-BITMAP] Transferred bitmap for ROI {i}: {cp.count_nonzero(roi_bitmap)}/{roi_size} nodes marked")
+            else:
+                # No bitmap provided - mark all nodes as valid (full ROI)
+                batch_roi_bitmap[i, :roi_size] = 1
+                logger.debug(f"[ROI-BITMAP] No bitmap for ROI {i}: marking all {roi_size} nodes as valid")
+
             # Store goal node for A* heuristic
             goal_nodes_array[i] = dst
 
@@ -1872,6 +1917,9 @@ class CUDADijkstra:
             'roi_maxy': roi_maxy,
             'roi_minz': roi_minz,
             'roi_maxz': roi_maxz,
+            # Phase 5: ROI bitmap for precise gating
+            'roi_bitmap': batch_roi_bitmap,
+            'roi_bitmap_stride': max_roi_size,
             # Phase 1: Stamp arrays and generation counter
             'dist_stamps': dist_stamps,
             'parent_stamps': parent_stamps,
@@ -1919,6 +1967,9 @@ class CUDADijkstra:
             logger.info(f"[CUDA-PATHFINDING] Routing to DELTA-STEPPING algorithm (delta={delta:.3f}mm)")
             return self._run_delta_stepping(data, K, delta, roi_batch)
 
+        # Log dispatcher decision
+        use_persistent_check = GPUConfig.USE_PERSISTENT_KERNEL if hasattr(GPUConfig, "USE_PERSISTENT_KERNEL") else False
+        logger.info(f"[CUDA-DISPATCHER] Delta-stepping: DISABLED | Persistent kernel: {"ENABLED" if use_persistent_check else "DISABLED"}")
         # Otherwise use BFS wavefront (fast but incorrect cost ordering)
         logger.info(f"[CUDA-WAVEFRONT] Starting BFS wavefront algorithm for {K} ROIs (WARNING: ignores cost ordering)")
 
@@ -2322,6 +2373,8 @@ class CUDADijkstra:
             indptr_stride,
             indices_stride,
             weights_stride,
+            data.get('total_cost', weights_arr),           # Negotiated costs or fallback to weights
+            data.get('total_cost_stride', weights_stride), # Stride for total_cost
             data['goal_nodes'],
             data['Nx'],            # P0-3: Lattice dimensions for procedural coords
             data['Ny'],
@@ -2338,6 +2391,9 @@ class CUDADijkstra:
             data['roi_maxy'],
             data['roi_minz'],
             data['roi_maxz'],
+            # Phase 5: ROI bitmap for precise gating
+            data['roi_bitmap'],
+            data['roi_bitmap_stride'],
         )
 
         # P0-5: Time kernel execution
@@ -3352,6 +3408,9 @@ class CUDADijkstra:
             data['roi_maxy'],
             data['roi_minz'],
             data['roi_maxz'],
+            # Phase 5: ROI bitmap for precise gating
+            data['roi_bitmap'],
+            data['roi_bitmap_stride'],
         )
 
         self.active_list_kernel((grid_size,), (block_size,), args)
@@ -3400,7 +3459,13 @@ class CUDADijkstra:
         logger.info(f"[CUDA-FALLBACK] Using CPU Dijkstra for {len(roi_batch)} ROIs")
 
         paths = []
-        for src, sink, indptr, indices, weights, size in roi_batch:
+        for roi_tuple in roi_batch:
+            # Handle both 6-element (old) and 7-element (new with roi_bitmap) tuples
+            if len(roi_tuple) == 7:
+                src, sink, indptr, indices, weights, size, roi_bitmap = roi_tuple
+            else:
+                src, sink, indptr, indices, weights, size = roi_tuple
+                roi_bitmap = None  # Old format without ROI bitmap
             # Transfer to CPU if needed
             if hasattr(indptr, 'get'):
                 indptr_cpu = indptr.get()
@@ -4127,7 +4192,13 @@ class CUDADijkstra:
         logger.info(f"[BIDIR-BATCH] Processing {len(roi_batch)} ROIs with bi-directional search")
 
         paths = []
-        for roi_idx, (src, dst, indptr, indices, weights, roi_size) in enumerate(roi_batch):
+        for roi_idx, roi_tuple in enumerate(roi_batch):
+            # Handle both 6-element (old) and 7-element (new with roi_bitmap) tuples
+            if len(roi_tuple) == 7:
+                src, dst, indptr, indices, weights, roi_size, roi_bitmap = roi_tuple
+            else:
+                src, dst, indptr, indices, weights, roi_size = roi_tuple
+                roi_bitmap = None  # Old format without ROI bitmap
             logger.info(f"[BIDIR-BATCH] ROI {roi_idx}/{len(roi_batch)}: src={src}, dst={dst}, size={roi_size}")
 
             # Convert to CuPy arrays
